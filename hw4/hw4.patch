diff --git a/linux-yocto-3.19.2/Makefile b/linux-yocto-3.19.2/Makefile
index 239f851..e49665a 100644
--- a/linux-yocto-3.19.2/Makefile
+++ b/linux-yocto-3.19.2/Makefile
@@ -1,7 +1,7 @@
 VERSION = 3
 PATCHLEVEL = 19
 SUBLEVEL = 2
-EXTRAVERSION = Group20Makefile
+EXTRAVERSION =
 NAME = Diseased Newt
 
 # *DOCUMENTATION*
diff --git a/linux-yocto-3.19.2/arch/x86/syscalls/syscall_32.tbl b/linux-yocto-3.19.2/arch/x86/syscalls/syscall_32.tbl
index 1e72f7a..b3560ec 100644
--- a/linux-yocto-3.19.2/arch/x86/syscalls/syscall_32.tbl
+++ b/linux-yocto-3.19.2/arch/x86/syscalls/syscall_32.tbl
@@ -365,5 +365,3 @@
 356	i386	memfd_create		sys_memfd_create
 357	i386	bpf			sys_bpf
 358	i386	execveat		sys_execveat			stub32_execveat
-359 i386    slob_free           sys_slob_free
-360 i386    slob_used           sys_slob_used
diff --git a/linux-yocto-3.19.2/include/linux/syscalls.h b/linux-yocto-3.19.2/include/linux/syscalls.h
index a73eac0..85893d7 100644
--- a/linux-yocto-3.19.2/include/linux/syscalls.h
+++ b/linux-yocto-3.19.2/include/linux/syscalls.h
@@ -882,7 +882,4 @@ asmlinkage long sys_execveat(int dfd, const char __user *filename,
 			const char __user *const __user *argv,
 			const char __user *const __user *envp, int flags);
 
-asmlinkage long sys_slob_free(void);
-asmlinkage long sys_slob_used(void);
-
 #endif
diff --git a/linux-yocto-3.19.2/mm/slob.c b/linux-yocto-3.19.2/mm/slob.c
index fed3fbe..96a8620 100644
--- a/linux-yocto-3.19.2/mm/slob.c
+++ b/linux-yocto-3.19.2/mm/slob.c
@@ -92,10 +92,6 @@ struct slob_block {
 };
 typedef struct slob_block slob_t;
 
-unsigned long slobPageCount = 0;
-unsigned long freeUnits     = 0;
-
-
 /*
  * All partially free slob pages go on these lists.
  */
@@ -272,13 +268,10 @@ static void *slob_page_alloc(struct page *sp, size_t size, int align)
 static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 {
 	struct page *sp;
-	struct page *spTemp = NULL;
 	struct list_head *prev;
 	struct list_head *slob_list;
-	struct list_head *temp;
 	slob_t *b = NULL;
 	unsigned long flags;
-	freeUnits = 0;
 
 	if (size < SLOB_BREAK1)
 		slob_list = &free_slob_small;
@@ -302,35 +295,20 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 		if (sp->units < SLOB_UNITS(size))
 			continue;
 
-		//first entry:
-		if (spTemp == NULL)
-			spTemp = sp;
-
-
-		//otherwise find the next best fit
-		if (sp->units < spTemp ->units)
-			spTemp = sp;
+		/* Attempt to alloc */
+		prev = sp->lru.prev;
+		b = slob_page_alloc(sp, size, align);
+		if (!b)
+			continue;
 
-	//attempt to alloc, in otherwords we have found a best fit page:
-	if (spTemp != NULL) {
-		b = slob_page_alloc(spTemp, size, align);
-	}
-	
-	//Loop through each linked list to find free space
-	temp = &free_slob_small;
-	list_for_each_entry(sp, temp, lru) {
-		freeUnits += sp->units;
-	}
-	temp = &free_slob_medium;
-	list_for_each_entry(sp, temp, lru) {
-		freeUnits += sp->units;
-	}
-	temp = &free_slob_large;
-	list_for_each_entry(sp, temp, lru) {
-		freeUnits += sp->units;
+		/* Improve fragment distribution and reduce our average
+		 * search time by starting our next search here. (see
+		 * Knuth vol 1, sec 2.5, pg 449) */
+		if (prev != slob_list->prev &&
+				slob_list->next != prev->next)
+			list_move_tail(slob_list, prev->next);
+		break;
 	}
-
-
 	spin_unlock_irqrestore(&slob_lock, flags);
 
 	/* Not enough space: must allocate a new page */
@@ -350,8 +328,6 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 		b = slob_page_alloc(sp, size, align);
 		BUG_ON(!b);
 		spin_unlock_irqrestore(&slob_lock, flags);
-
-		slobPageCount++;
 	}
 	if (unlikely((gfp & __GFP_ZERO) && b))
 		memset(b, 0, size);
@@ -386,8 +362,6 @@ static void slob_free(void *block, int size)
 		__ClearPageSlab(sp);
 		page_mapcount_reset(sp);
 		slob_free_pages(b, 0);
-
-		slobPageCount--;
 		return;
 	}
 
@@ -656,17 +630,6 @@ struct kmem_cache kmem_cache_boot = {
 	.align = ARCH_KMALLOC_MINALIGN,
 };
 
-asmlinkage long sys_slob_used(void) {
-
-    // Used pages = Page Size * Total Pages
-    long slob_total_used = SLOB_UNITS(PAGE_SIZE) * slobPageCount;
-    return slob_total_used;
-}
-
-asmlinkage long sys_slob_free(void) {
-    return freeUnits;
-}
-
 void __init kmem_cache_init(void)
 {
 	kmem_cache = &kmem_cache_boot;
@@ -676,4 +639,4 @@ void __init kmem_cache_init(void)
 void __init kmem_cache_init_late(void)
 {
 	slab_state = FULL;
-}
\ No newline at end of file
+}
